{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 64                            # 배치 크기\n",
    "epochs = 100                            # 학습 epochs\n",
    "latent_dim = 256                        # 단어 인코딩 축소 차원 \n",
    "n_max_sample = 10000                    # 학습 시킬 최대 샘플 수\n",
    "data_path = './data/eng-fra/fra.txt'    # 데이터 텍스트 파일 경로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전체 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.\\tVa !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #1158250 (Wittydev)',\n",
       " 'Hi.\\tSalut !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #509819 (Aiji)',\n",
       " 'Hi.\\tSalut.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #4320462 (gillux)',\n",
       " 'Run!\\tCours\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906331 (sacredceltic)',\n",
       " 'Run!\\tCourez\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #906328 (papabear) & #906332 (sacredceltic)',\n",
       " 'Who?\\tQui ?\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2083030 (CK) & #4366796 (gillux)',\n",
       " 'Wow!\\tÇa alors\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #52027 (Zifre) & #374631 (zmoo)',\n",
       " 'Fire!\\tAu feu !\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1829639 (Spamster) & #4627939 (sacredceltic)',\n",
       " \"Help!\\tÀ l'aide\\u202f!\\tCC-BY 2.0 (France) Attribution: tatoeba.org #435084 (lukaszpp) & #128430 (sysko)\",\n",
       " 'Jump.\\tSaute.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #631038 (Shishir) & #2416938 (Micsmithel)']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인풋, 타겟 텍스트 데이터 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_txts = []\n",
    "y_txts = []\n",
    "x_chars_uni = set()\n",
    "y_chars_uni = set()\n",
    "n_sample = min(n_max_sample, len(lines) - 1)    \n",
    "\n",
    "for line in lines[:n_sample]:\n",
    "    x_txt, y_txt, _ = line.split('\\t')\n",
    "    y_txt = '\\t' + y_txt + '\\n'\n",
    "    x_txts.append(x_txt)\n",
    "    y_txts.append(y_txt)\n",
    "    \n",
    "    for char in x_txt:\n",
    "        if char not in x_chars_uni:\n",
    "            x_chars_uni.add(char)\n",
    "    for char in y_txt:\n",
    "        if char not in y_chars_uni:\n",
    "            y_chars_uni.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go.', 'Hi.', 'Hi.', 'Run!', 'Run!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\tVa !\\n',\n",
       " '\\tSalut !\\n',\n",
       " '\\tSalut.\\n',\n",
       " '\\tCours\\u202f!\\n',\n",
       " '\\tCourez\\u202f!\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_txts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " '!',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " 'é'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_chars_uni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t',\n",
       " '\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '5',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'Y',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '\\xa0',\n",
       " '«',\n",
       " '»',\n",
       " 'À',\n",
       " 'Ç',\n",
       " 'É',\n",
       " 'Ê',\n",
       " 'à',\n",
       " 'â',\n",
       " 'ç',\n",
       " 'è',\n",
       " 'é',\n",
       " 'ê',\n",
       " 'ë',\n",
       " 'î',\n",
       " 'ï',\n",
       " 'ô',\n",
       " 'ù',\n",
       " 'û',\n",
       " 'œ',\n",
       " '\\u2009',\n",
       " '’',\n",
       " '\\u202f'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_chars_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰 단위 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chars_uni = sorted(list(x_chars_uni))\n",
    "y_chars_uni = sorted(list(y_chars_uni))\n",
    "n_encoder_tokens = len(x_chars_uni)\n",
    "n_decoder_tokens = len(y_chars_uni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "유니크 인코더 토큰 글자 수:  71\n",
      "유니크 디코더 토큰 글자 수:  93\n"
     ]
    }
   ],
   "source": [
    "print(\"유니크 인코더 토큰 글자 수: \", n_encoder_tokens)\n",
    "print(\"유니크 디코더 토큰 글자 수: \", n_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코더 문장내 최대 문자 수:  15\n"
     ]
    }
   ],
   "source": [
    "max_encoder_seq_len = 0\n",
    "for txt in x_txts:\n",
    "    txt_len = len(txt)\n",
    "    max_encoder_seq_len = max(txt_len, \n",
    "                              max_encoder_seq_len)\n",
    "print(\"인코더 문장내 최대 문자 수: \", max_encoder_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디코더 문장내 최대 문자 수:  59\n"
     ]
    }
   ],
   "source": [
    "max_decoder_seq_len = 0\n",
    "for txt in y_txts:\n",
    "    txt_len = len(txt)\n",
    "    max_decoder_seq_len = max(txt_len, \n",
    "                              max_decoder_seq_len)\n",
    "print(\"디코더 문장내 최대 문자 수: \", max_decoder_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 토큰 별 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_token_idx = {}\n",
    "for idx, char in enumerate(x_chars_uni):\n",
    "    x_token_idx[char] = idx\n",
    "    \n",
    "y_token_idx ={}\n",
    "for idx, char in enumerate(y_chars_uni):\n",
    "    y_token_idx[char] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 0,\n",
       " '!': 1,\n",
       " '$': 2,\n",
       " '%': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " ',': 6,\n",
       " '-': 7,\n",
       " '.': 8,\n",
       " '0': 9,\n",
       " '1': 10,\n",
       " '2': 11,\n",
       " '3': 12,\n",
       " '5': 13,\n",
       " '6': 14,\n",
       " '7': 15,\n",
       " '8': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " '?': 19,\n",
       " 'A': 20,\n",
       " 'B': 21,\n",
       " 'C': 22,\n",
       " 'D': 23,\n",
       " 'E': 24,\n",
       " 'F': 25,\n",
       " 'G': 26,\n",
       " 'H': 27,\n",
       " 'I': 28,\n",
       " 'J': 29,\n",
       " 'K': 30,\n",
       " 'L': 31,\n",
       " 'M': 32,\n",
       " 'N': 33,\n",
       " 'O': 34,\n",
       " 'P': 35,\n",
       " 'Q': 36,\n",
       " 'R': 37,\n",
       " 'S': 38,\n",
       " 'T': 39,\n",
       " 'U': 40,\n",
       " 'V': 41,\n",
       " 'W': 42,\n",
       " 'Y': 43,\n",
       " 'a': 44,\n",
       " 'b': 45,\n",
       " 'c': 46,\n",
       " 'd': 47,\n",
       " 'e': 48,\n",
       " 'f': 49,\n",
       " 'g': 50,\n",
       " 'h': 51,\n",
       " 'i': 52,\n",
       " 'j': 53,\n",
       " 'k': 54,\n",
       " 'l': 55,\n",
       " 'm': 56,\n",
       " 'n': 57,\n",
       " 'o': 58,\n",
       " 'p': 59,\n",
       " 'q': 60,\n",
       " 'r': 61,\n",
       " 's': 62,\n",
       " 't': 63,\n",
       " 'u': 64,\n",
       " 'v': 65,\n",
       " 'w': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69,\n",
       " 'é': 70}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\t': 0,\n",
       " '\\n': 1,\n",
       " ' ': 2,\n",
       " '!': 3,\n",
       " '$': 4,\n",
       " '%': 5,\n",
       " '&': 6,\n",
       " \"'\": 7,\n",
       " '(': 8,\n",
       " ')': 9,\n",
       " ',': 10,\n",
       " '-': 11,\n",
       " '.': 12,\n",
       " '0': 13,\n",
       " '1': 14,\n",
       " '2': 15,\n",
       " '3': 16,\n",
       " '5': 17,\n",
       " '8': 18,\n",
       " '9': 19,\n",
       " ':': 20,\n",
       " '?': 21,\n",
       " 'A': 22,\n",
       " 'B': 23,\n",
       " 'C': 24,\n",
       " 'D': 25,\n",
       " 'E': 26,\n",
       " 'F': 27,\n",
       " 'G': 28,\n",
       " 'H': 29,\n",
       " 'I': 30,\n",
       " 'J': 31,\n",
       " 'K': 32,\n",
       " 'L': 33,\n",
       " 'M': 34,\n",
       " 'N': 35,\n",
       " 'O': 36,\n",
       " 'P': 37,\n",
       " 'Q': 38,\n",
       " 'R': 39,\n",
       " 'S': 40,\n",
       " 'T': 41,\n",
       " 'U': 42,\n",
       " 'V': 43,\n",
       " 'Y': 44,\n",
       " 'a': 45,\n",
       " 'b': 46,\n",
       " 'c': 47,\n",
       " 'd': 48,\n",
       " 'e': 49,\n",
       " 'f': 50,\n",
       " 'g': 51,\n",
       " 'h': 52,\n",
       " 'i': 53,\n",
       " 'j': 54,\n",
       " 'k': 55,\n",
       " 'l': 56,\n",
       " 'm': 57,\n",
       " 'n': 58,\n",
       " 'o': 59,\n",
       " 'p': 60,\n",
       " 'q': 61,\n",
       " 'r': 62,\n",
       " 's': 63,\n",
       " 't': 64,\n",
       " 'u': 65,\n",
       " 'v': 66,\n",
       " 'x': 67,\n",
       " 'y': 68,\n",
       " 'z': 69,\n",
       " '\\xa0': 70,\n",
       " '«': 71,\n",
       " '»': 72,\n",
       " 'À': 73,\n",
       " 'Ç': 74,\n",
       " 'É': 75,\n",
       " 'Ê': 76,\n",
       " 'à': 77,\n",
       " 'â': 78,\n",
       " 'ç': 79,\n",
       " 'è': 80,\n",
       " 'é': 81,\n",
       " 'ê': 82,\n",
       " 'ë': 83,\n",
       " 'î': 84,\n",
       " 'ï': 85,\n",
       " 'ô': 86,\n",
       " 'ù': 87,\n",
       " 'û': 88,\n",
       " 'œ': 89,\n",
       " '\\u2009': 90,\n",
       " '’': 91,\n",
       " '\\u202f': 92}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_token_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 영행렬 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_x_data = np.zeros(\n",
    "                            (len(x_txts), \n",
    "                             max_encoder_seq_len, \n",
    "                             n_encoder_tokens),\n",
    "                        dtype='float32')\n",
    "decoder_x_data = np.zeros(\n",
    "                            (len(x_txts), \n",
    "                             max_decoder_seq_len, \n",
    "                             n_decoder_tokens),\n",
    "                        dtype='float32')\n",
    "decoder_y_data = np.zeros(\n",
    "                            (len(x_txts), \n",
    "                             max_decoder_seq_len, \n",
    "                             n_decoder_tokens),\n",
    "                        dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인풋 데이터 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, x_txt in enumerate(x_txts):\n",
    "    \n",
    "    for t, char in enumerate(x_txt):\n",
    "        encoder_x_data[i, t, x_token_idx[char]] = 1.\n",
    "    encoder_x_data[i, t + 1:, x_token_idx[' ']] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 타겟 데이터 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y_txt in enumerate(y_txts):\n",
    "       \n",
    "    for t, char in enumerate(y_txt):\n",
    "        decoder_x_data[i, t, y_token_idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_y_data[i, t - 1, y_token_idx[char]] = 1.\n",
    "            \n",
    "    decoder_x_data[i, t + 1:, y_token_idx[' ']] = 1.\n",
    "    decoder_y_data[i, t:, y_token_idx[' ']] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "encoder_inputs = Input(shape=(None, n_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 71)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n"
     ]
    }
   ],
   "source": [
    "print(encoder_inputs.shape)\n",
    "print(encoder_outs.shape)\n",
    "print(state_h.shape)\n",
    "print(state_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, n_decoder_tokens))\n",
    "decoder = LSTM(latent_dim, \n",
    "                return_sequences=True, \n",
    "                return_state=True)\n",
    "decoder_outs, _, _ = decoder(decoder_inputs,\n",
    "                             initial_state=encoder_states)\n",
    "decoder_dense = TimeDistributed(Dense(n_decoder_tokens, \n",
    "                                      activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, None, 93)\n",
      "(None, None, 93)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_inputs.shape)\n",
    "print(decoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인코더-디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, None, 71)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, None, 93)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 335872      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  358400      input_3[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 93)     23901       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 718,173\n",
      "Trainable params: 718,173\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], \n",
    "              decoder_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형 적합 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 38s 259ms/step - loss: 1.5352 - accuracy: 0.6965 - val_loss: 1.1027 - val_accuracy: 0.7016\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 30s 237ms/step - loss: 0.8940 - accuracy: 0.7578 - val_loss: 0.8346 - val_accuracy: 0.7722\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - ETA: 0s - loss: 0.7006 - accuracy: 0.8040"
     ]
    }
   ],
   "source": [
    "model.fit([encoder_x_data, decoder_x_data], decoder_y_data,\n",
    "          batch_size=n_batch,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 샘플링 모형 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, \n",
    "                         decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리버스 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_x_char_idx = {}\n",
    "for char, idx in x_token_idx.items():\n",
    "    reverse_x_char_idx[idx] = char\n",
    "    \n",
    "reverse_y_char_idx ={}\n",
    "for char, idx in y_token_idx.items():\n",
    "    reverse_y_char_idx[idx] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ' ',\n",
       " 1: '!',\n",
       " 2: '$',\n",
       " 3: '%',\n",
       " 4: '&',\n",
       " 5: \"'\",\n",
       " 6: ',',\n",
       " 7: '-',\n",
       " 8: '.',\n",
       " 9: '0',\n",
       " 10: '1',\n",
       " 11: '2',\n",
       " 12: '3',\n",
       " 13: '5',\n",
       " 14: '6',\n",
       " 15: '7',\n",
       " 16: '8',\n",
       " 17: '9',\n",
       " 18: ':',\n",
       " 19: '?',\n",
       " 20: 'A',\n",
       " 21: 'B',\n",
       " 22: 'C',\n",
       " 23: 'D',\n",
       " 24: 'E',\n",
       " 25: 'F',\n",
       " 26: 'G',\n",
       " 27: 'H',\n",
       " 28: 'I',\n",
       " 29: 'J',\n",
       " 30: 'K',\n",
       " 31: 'L',\n",
       " 32: 'M',\n",
       " 33: 'N',\n",
       " 34: 'O',\n",
       " 35: 'P',\n",
       " 36: 'Q',\n",
       " 37: 'R',\n",
       " 38: 'S',\n",
       " 39: 'T',\n",
       " 40: 'U',\n",
       " 41: 'V',\n",
       " 42: 'W',\n",
       " 43: 'Y',\n",
       " 44: 'a',\n",
       " 45: 'b',\n",
       " 46: 'c',\n",
       " 47: 'd',\n",
       " 48: 'e',\n",
       " 49: 'f',\n",
       " 50: 'g',\n",
       " 51: 'h',\n",
       " 52: 'i',\n",
       " 53: 'j',\n",
       " 54: 'k',\n",
       " 55: 'l',\n",
       " 56: 'm',\n",
       " 57: 'n',\n",
       " 58: 'o',\n",
       " 59: 'p',\n",
       " 60: 'q',\n",
       " 61: 'r',\n",
       " 62: 's',\n",
       " 63: 't',\n",
       " 64: 'u',\n",
       " 65: 'v',\n",
       " 66: 'w',\n",
       " 67: 'x',\n",
       " 68: 'y',\n",
       " 69: 'z',\n",
       " 70: 'é'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_x_char_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '\\t',\n",
       " 1: '\\n',\n",
       " 2: ' ',\n",
       " 3: '!',\n",
       " 4: '$',\n",
       " 5: '%',\n",
       " 6: '&',\n",
       " 7: \"'\",\n",
       " 8: '(',\n",
       " 9: ')',\n",
       " 10: ',',\n",
       " 11: '-',\n",
       " 12: '.',\n",
       " 13: '0',\n",
       " 14: '1',\n",
       " 15: '2',\n",
       " 16: '3',\n",
       " 17: '5',\n",
       " 18: '8',\n",
       " 19: '9',\n",
       " 20: ':',\n",
       " 21: '?',\n",
       " 22: 'A',\n",
       " 23: 'B',\n",
       " 24: 'C',\n",
       " 25: 'D',\n",
       " 26: 'E',\n",
       " 27: 'F',\n",
       " 28: 'G',\n",
       " 29: 'H',\n",
       " 30: 'I',\n",
       " 31: 'J',\n",
       " 32: 'K',\n",
       " 33: 'L',\n",
       " 34: 'M',\n",
       " 35: 'N',\n",
       " 36: 'O',\n",
       " 37: 'P',\n",
       " 38: 'Q',\n",
       " 39: 'R',\n",
       " 40: 'S',\n",
       " 41: 'T',\n",
       " 42: 'U',\n",
       " 43: 'V',\n",
       " 44: 'Y',\n",
       " 45: 'a',\n",
       " 46: 'b',\n",
       " 47: 'c',\n",
       " 48: 'd',\n",
       " 49: 'e',\n",
       " 50: 'f',\n",
       " 51: 'g',\n",
       " 52: 'h',\n",
       " 53: 'i',\n",
       " 54: 'j',\n",
       " 55: 'k',\n",
       " 56: 'l',\n",
       " 57: 'm',\n",
       " 58: 'n',\n",
       " 59: 'o',\n",
       " 60: 'p',\n",
       " 61: 'q',\n",
       " 62: 'r',\n",
       " 63: 's',\n",
       " 64: 't',\n",
       " 65: 'u',\n",
       " 66: 'v',\n",
       " 67: 'x',\n",
       " 68: 'y',\n",
       " 69: 'z',\n",
       " 70: '\\xa0',\n",
       " 71: '«',\n",
       " 72: '»',\n",
       " 73: 'À',\n",
       " 74: 'Ç',\n",
       " 75: 'É',\n",
       " 76: 'Ê',\n",
       " 77: 'à',\n",
       " 78: 'â',\n",
       " 79: 'ç',\n",
       " 80: 'è',\n",
       " 81: 'é',\n",
       " 82: 'ê',\n",
       " 83: 'ë',\n",
       " 84: 'î',\n",
       " 85: 'ï',\n",
       " 86: 'ô',\n",
       " 87: 'ù',\n",
       " 88: 'û',\n",
       " 89: 'œ',\n",
       " 90: '\\u2009',\n",
       " 91: '’',\n",
       " 92: '\\u202f'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_y_char_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과값 디코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    y_seq = np.zeros((1, 1, n_decoder_tokens))\n",
    "    y_seq[0, 0, y_token_idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [y_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_y_char_idx[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        y_seq = np.zeros((1, 1, n_decoder_tokens))\n",
    "        y_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Va !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Hi.\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Cours !\n",
      "\n",
      "-\n",
      "Input sentence: Who?\n",
      "Decoded sentence: Qui ?\n",
      "\n",
      "-\n",
      "Input sentence: Wow!\n",
      "Decoded sentence: Ça alors !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Au feu !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: À l'aide !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Saute.\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Arrête-toi !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Attends !\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuis.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuis.\n",
      "\n",
      "-\n",
      "Input sentence: Go on.\n",
      "Decoded sentence: Poursuis.\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: Hello!\n",
      "Decoded sentence: Salut !\n",
      "\n",
      "-\n",
      "Input sentence: I see.\n",
      "Decoded sentence: Je comprends.\n",
      "\n",
      "-\n",
      "Input sentence: I try.\n",
      "Decoded sentence: J'essaye.\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: J'ai gagné !\n",
      "\n",
      "-\n",
      "Input sentence: I won!\n",
      "Decoded sentence: J'ai gagné !\n",
      "\n",
      "-\n",
      "Input sentence: I won.\n",
      "Decoded sentence: J’ai gagné.\n",
      "\n",
      "-\n",
      "Input sentence: Oh no!\n",
      "Decoded sentence: Oh non !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "-\n",
      "Input sentence: Attack!\n",
      "Decoded sentence: Attaquez !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Cheers!\n",
      "Decoded sentence: Santé !\n",
      "\n",
      "-\n",
      "Input sentence: Get up.\n",
      "Decoded sentence: Lève-toi.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Va, maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Va, maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Go now.\n",
      "Decoded sentence: Va, maintenant.\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris !\n",
      "\n",
      "-\n",
      "Input sentence: Got it!\n",
      "Decoded sentence: Compris !\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Compris ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Compris ?\n",
      "\n",
      "-\n",
      "Input sentence: Got it?\n",
      "Decoded sentence: Compris ?\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "-\n",
      "Input sentence: Hop in.\n",
      "Decoded sentence: Montez.\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi dans vos bras !\n",
      "\n",
      "-\n",
      "Input sentence: Hug me.\n",
      "Decoded sentence: Serrez-moi dans vos bras !\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "-\n",
      "Input sentence: I fell.\n",
      "Decoded sentence: Je suis tombée.\n",
      "\n",
      "-\n",
      "Input sentence: I fled.\n",
      "Decoded sentence: J'ai fui.\n",
      "\n",
      "-\n",
      "Input sentence: I know.\n",
      "Decoded sentence: Je sais.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis partie.\n",
      "\n",
      "-\n",
      "Input sentence: I left.\n",
      "Decoded sentence: Je suis partie.\n",
      "\n",
      "-\n",
      "Input sentence: I lied.\n",
      "Decoded sentence: J'ai menti.\n",
      "\n",
      "-\n",
      "Input sentence: I lost.\n",
      "Decoded sentence: J'ai perdu.\n",
      "\n",
      "-\n",
      "Input sentence: I paid.\n",
      "Decoded sentence: J’ai payé.\n",
      "\n",
      "-\n",
      "Input sentence: I'm 19.\n",
      "Decoded sentence: J'ai fait marane.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je vais bien.\n",
      "\n",
      "-\n",
      "Input sentence: I'm OK.\n",
      "Decoded sentence: Je vais bien.\n",
      "\n",
      "-\n",
      "Input sentence: Listen.\n",
      "Decoded sentence: Écoutez !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: No way!\n",
      "Decoded sentence: C'est pas possible !\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Ah bon ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Ah bon ?\n",
      "\n",
      "-\n",
      "Input sentence: Really?\n",
      "Decoded sentence: Ah bon ?\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merci.\n",
      "\n",
      "-\n",
      "Input sentence: Thanks.\n",
      "Decoded sentence: Merci.\n",
      "\n",
      "-\n",
      "Input sentence: We try.\n",
      "Decoded sentence: On essaye.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: We won.\n",
      "Decoded sentence: Nous avons gagné.\n",
      "\n",
      "-\n",
      "Input sentence: Ask Tom.\n",
      "Decoded sentence: Demande à Tom.\n",
      "\n",
      "-\n",
      "Input sentence: Awesome!\n",
      "Decoded sentence: Fantastique !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois prudente !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois prudente !\n",
      "\n",
      "-\n",
      "Input sentence: Be calm.\n",
      "Decoded sentence: Sois prudente !\n",
      "\n",
      "-\n",
      "Input sentence: Be cool.\n",
      "Decoded sentence: Sois détendu !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be fair.\n",
      "Decoded sentence: Soyez équitable !\n",
      "\n",
      "-\n",
      "Input sentence: Be kind.\n",
      "Decoded sentence: Sois gentil.\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentils !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentils !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentils !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentils !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentils !\n",
      "\n",
      "-\n",
      "Input sentence: Be nice.\n",
      "Decoded sentence: Soyez gentils !\n",
      "\n",
      "-\n",
      "Input sentence: Beat it.\n",
      "Decoded sentence: Dégage !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call me.\n",
      "Decoded sentence: Appelez-moi !\n",
      "\n",
      "-\n",
      "Input sentence: Call us.\n",
      "Decoded sentence: Appelle-nous !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_idx in range(100):\n",
    "    x_seq = encoder_x_data[seq_idx: seq_idx + 1]\n",
    "    decoded_sentence = decode_sequence(x_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', x_txts[seq_idx])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통합 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 시드 설정\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "\n",
    "n_batch = 64                            # 배치 크기\n",
    "epochs = 100                            # 학습 epochs\n",
    "latent_dim = 256                        # 단어 인코딩 축소 차원 \n",
    "n_max_sample = 10000                    # 학습 시킬 최대 샘플 수\n",
    "data_path = './data/eng-fra/fra.txt'    # 데이터 텍스트 파일 경로\n",
    "\n",
    "# 데이터 불러오기\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "# 인풋, 타겟 데이터 정리\n",
    "x_txts = []\n",
    "y_txts = []\n",
    "x_chars_uni = set()\n",
    "y_chars_uni = set()\n",
    "n_sample = min(n_max_sample, len(lines) - 1)    \n",
    "\n",
    "for line in lines[:n_sample]:\n",
    "    x_txt, y_txt, _ = line.split('\\t')\n",
    "    y_txt = '\\t' + y_txt + '\\n'\n",
    "    x_txts.append(x_txt)\n",
    "    y_txts.append(y_txt)\n",
    "    \n",
    "    for char in x_txt:\n",
    "        if char not in x_chars_uni:\n",
    "            x_chars_uni.add(char)\n",
    "    for char in y_txt:\n",
    "        if char not in y_chars_uni:\n",
    "            y_chars_uni.add(char)\n",
    "\n",
    "# 토큰 정리\n",
    "x_chars_uni = sorted(list(x_chars_uni))\n",
    "y_chars_uni = sorted(list(y_chars_uni))\n",
    "n_encoder_tokens = len(x_chars_uni)\n",
    "n_decoder_tokens = len(y_chars_uni)\n",
    "print(\"유니크 인코더 토큰 글자 수: \", n_encoder_tokens)\n",
    "print(\"유니크 디코더 토큰 글자 수: \", n_decoder_tokens)\n",
    "\n",
    "max_encoder_seq_len = 0\n",
    "for txt in x_txts:\n",
    "    txt_len = len(txt)\n",
    "    max_encoder_seq_len = max(txt_len, \n",
    "                              max_encoder_seq_len)\n",
    "print(\"인코더 문장내 최대 문자 수: \", max_encoder_seq_len)\n",
    "\n",
    "max_decoder_seq_len = 0\n",
    "for txt in y_txts:\n",
    "    txt_len = len(txt)\n",
    "    max_decoder_seq_len = max(txt_len, \n",
    "                              max_decoder_seq_len)\n",
    "print(\"디코더 문장내 최대 문자 수: \", max_decoder_seq_len)\n",
    "\n",
    "# 토큰 인덱스\n",
    "x_token_idx = {}\n",
    "for idx, char in enumerate(x_chars_uni):\n",
    "    x_token_idx[char] = idx\n",
    "    \n",
    "y_token_idx ={}\n",
    "for idx, char in enumerate(y_chars_uni):\n",
    "    y_token_idx[char] = idx\n",
    "    \n",
    "# 영행렬 만들기\n",
    "encoder_x_data = np.zeros(\n",
    "                            (len(x_txts), \n",
    "                             max_encoder_seq_len, \n",
    "                             n_encoder_tokens),\n",
    "                        dtype='float32')\n",
    "decoder_x_data = np.zeros(\n",
    "                            (len(x_txts), \n",
    "                             max_decoder_seq_len, \n",
    "                             n_decoder_tokens),\n",
    "                        dtype='float32')\n",
    "decoder_y_data = np.zeros(\n",
    "                            (len(x_txts), \n",
    "                             max_decoder_seq_len, \n",
    "                             n_decoder_tokens),\n",
    "                        dtype='float32')\n",
    "# 인풋 데이터 행렬\n",
    "for i, x_txt in enumerate(x_txts):\n",
    "    \n",
    "    for t, char in enumerate(x_txt):\n",
    "        encoder_x_data[i, t, x_token_idx[char]] = 1.\n",
    "    encoder_x_data[i, t + 1:, x_token_idx[' ']] = 1.\n",
    "\n",
    "# 타겟 데이터 행렬\n",
    "for i, y_txt in enumerate(y_txts):\n",
    "       \n",
    "    for t, char in enumerate(y_txt):\n",
    "        decoder_x_data[i, t, y_token_idx[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_y_data[i, t - 1, y_token_idx[char]] = 1.\n",
    "            \n",
    "    decoder_x_data[i, t + 1:, y_token_idx[' ']] = 1.\n",
    "    decoder_y_data[i, t:, y_token_idx[' ']] = 1.\n",
    "    \n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(None, n_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# 디코더\n",
    "decoder_inputs = Input(shape=(None, n_decoder_tokens))\n",
    "decoder = LSTM(latent_dim, \n",
    "                return_sequences=True, \n",
    "                return_state=True)\n",
    "decoder_outs, _, _ = decoder(decoder_inputs,\n",
    "                             initial_state=encoder_states)\n",
    "decoder_dense = TimeDistributed(Dense(n_decoder_tokens, \n",
    "                                      activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_outs)\n",
    "\n",
    "# 인코더 디코더\n",
    "model = Model([encoder_inputs, decoder_inputs], \n",
    "              decoder_outputs)\n",
    "model.summary()\n",
    "\n",
    "# 모형 컴파일\n",
    "model.compile(optimizer='rmsprop', \n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "model.fit([encoder_x_data, decoder_x_data], decoder_y_data,\n",
    "          batch_size=n_batch,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "\n",
    "# 추론 모형 생성\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, \n",
    "                         decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# 리버스 인덱스\n",
    "reverse_x_char_idx = {}\n",
    "for char, idx in x_token_idx.items():\n",
    "    reverse_x_char_idx[idx] = char\n",
    "    \n",
    "reverse_y_char_idx ={}\n",
    "for char, idx in y_token_idx.items():\n",
    "    reverse_y_char_idx[idx] = char\n",
    "\n",
    "# 결과값 디코딩\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    y_seq = np.zeros((1, 1, n_decoder_tokens))\n",
    "    y_seq[0, 0, y_token_idx['\\t']] = 1.\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [y_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_y_char_idx[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        y_seq = np.zeros((1, 1, n_decoder_tokens))\n",
    "        y_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "\n",
    "# 최종 결과 확인\n",
    "for seq_idx in range(100):\n",
    "    x_seq = encoder_x_data[seq_idx: seq_idx + 1]\n",
    "    decoded_sentence = decode_sequence(x_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', x_txts[seq_idx])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
